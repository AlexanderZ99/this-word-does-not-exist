{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urban_dictionary_scraper\n",
    "import logging\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import stanza\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import io\n",
    "import itertools\n",
    "import numpy as np\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "session = urban_dictionary.get_session(throttle=0.1, expiry = (7*24*3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "all_urls = urban_dictionary_scraper.fetch_all_word_urls(session)\n",
    "with open(\"all_urls.pickle\", \"wb\") as f:\n",
    "    pickle.dump(all_urls, f, pickle.HIGHEST_PROTOCOL)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"all_urls.pickle\", \"rb\") as f:\n",
    "    to_fetch = pickle.load(f)\n",
    "    \n",
    "with open(\"all_words.pickle\", \"rb\") as f:\n",
    "    already_done = pickle.load(f)\n",
    "    for key in already_done.keys():\n",
    "        del to_fetch[key]\n",
    "        \n",
    "done = 100 * len(already_done) / (len(already_done) + len(to_fetch))\n",
    "print(f\"Done {done:.2f} percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ThreadPool(5)\n",
    "#with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "try:\n",
    "    fetch_all_definitions(session, to_fetch, already_done, save_interval=10000, executor=t)    \n",
    "finally:\n",
    "    t.terminate()\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(\"data/all_words.pickle\", \"rb\") as f:\n",
    "    words = pickle.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clean(word, min_upvotes=20, max_word_length=40, max_symbols=2, allow_upper=False, min_word_length=4):\n",
    "    if word.upvotes < min_upvotes:\n",
    "        return False\n",
    "    elif len(word.word) > max_word_length:\n",
    "        return False\n",
    "    elif len(word.word) < min_word_length:\n",
    "        return False\n",
    "    elif len(re.findall(r\"[^\\w .]\", word.word)) > max_symbols:\n",
    "        return False\n",
    "    elif not allow_upper and word.word.isupper():\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "clean_list = [\n",
    "    (k, urban_dictionary_scraper.UrbanDictionaryWord(\n",
    "        title=e.title,\n",
    "        url=e.url,\n",
    "        definitions=[x for x in e.definitions if is_clean(x)],\n",
    "    ))\n",
    "    for k,e in words.items() if any(is_clean(x) for x in e.definitions)\n",
    "]\n",
    "random.shuffle(clean_list)\n",
    "cleaned_words = OrderedDict(clean_list)\n",
    "\n",
    "print(f\"Words reduced by {len(cleaned_words) / len(words)}\")\n",
    "\n",
    "with open(\"data/cleaned_words_all_def_min_upvotes_20_max_len_40_min_len_4_no_upper_randomized.pickle\", \"wb\") as f:\n",
    "    pickle.dump(cleaned_words, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(processors=\"tokenize,pos\")\n",
    "def proper_noun_guess(word):\n",
    "    query = word.title.upper().strip().strip(\"\\\"\").strip()\n",
    "    for definition in word.definitions:\n",
    "        try:\n",
    "            doc = nlp(definition.examples[0])\n",
    "        except IndexError:\n",
    "            print(f\"{query}: INDEX ERROR\")\n",
    "            return False\n",
    "        for sentence in doc.sentences:\n",
    "            last_prop = []\n",
    "            for word in sentence.words:\n",
    "                if word.upos == \"PROPN\":\n",
    "                    last_prop.append(word.text.upper())\n",
    "                    if query == \" \".join(last_prop):\n",
    "                        return True\n",
    "                else:\n",
    "                    last_prop = []\n",
    "               \n",
    "pbar = tqdm(total=len(cleaned_words.values()))\n",
    "for i, item in enumerate(cleaned_words.values()):\n",
    "    t = proper_noun_guess(item)\n",
    "    if t:\n",
    "        print(f\"{item.title}: {t}\")\n",
    "        \n",
    "    pbar.update()\n",
    "    \n",
    "    if i > 1000:\n",
    "        break\n",
    "    \n",
    "proper_noun_guess(next(iter(words.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defns = pd.DataFrame(\n",
    "    [\n",
    "        [e.word, e.meaning, e.examples[0], e.creation_epoch, e.upvotes, e.downvotes]\n",
    "        for e in itertools.chain.from_iterable(e.definitions for e in words.values())\n",
    "    ],\n",
    "    columns=[\"word\", \"meaning\", \"example\", \"creation_epoch\", \"upvotes\", \"downvotes\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_prior = 20\n",
    "defns[\"smoothed_upvotes\"] = defns[\"upvotes\"] / (defns[\"upvotes\"] + defns[\"downvotes\"] + smoothing_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defns[\"smoothed_upvotes\"].quantile(np.linspace(0.1, 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_defs = defns[:]\n",
    "# cleaned_defs = cleaned_defs[cleaned_defs[\"smoothed_upvotes\"] >= 0.2]\n",
    "cleaned_defs = cleaned_defs[cleaned_defs[\"upvotes\"] >= 20]\n",
    "cleaned_defs = cleaned_defs[cleaned_defs.word.str.len() <= 40]\n",
    "cleaned_defs = cleaned_defs[cleaned_defs.word.str.len() >= 4]\n",
    "cleaned_defs = cleaned_defs[~cleaned_defs.word.str.isupper()]\n",
    "\n",
    "cleaned_defs = cleaned_defs[cleaned_defs.word.str.count(\"[^\\w .]\") <= 2]\n",
    "print(f\"Reduction from {len(defns)} to {len(cleaned_defs)} ({len(cleaned_defs) / len(defns)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_defs[cleaned_defs.word.str.upper().str.contains(\",\")].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defns.word.str.count(\"[^\\w ].\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defns[defns.word.str.len() > 40].sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defns[defns.word.str.count(\"[^\\w .]\") > 2].sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(defns[\"meaning\"].str.len() + defns[\"example\"].str.len()).quantile(np.linspace(0.01, 1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lng_defs = defns[defns[\"meaning\"].str.len() > 985]\n",
    "(lng_defs[\"upvotes\"] + lng_defs[\"downvotes\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lng_defs = defns[defns[\"meaning\"].str.len() < 985]\n",
    "(lng_defs[\"upvotes\"] + lng_defs[\"downvotes\"]).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
