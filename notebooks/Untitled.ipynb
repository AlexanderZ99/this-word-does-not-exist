{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 116kB [00:00, 8.51MB/s]                    \n",
      "2020-04-30 23:56:01 INFO: Downloading default packages for language: en (English)...\n",
      "2020-04-30 23:56:02 INFO: File exists: /home/tdimson/stanza_resources/en/default.zip.\n",
      "2020-04-30 23:56:05 INFO: Finished downloading models and saved to /home/tdimson/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import stanza\n",
    "from collections import Counter\n",
    "stanza.download('en')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import datasets\n",
    "import pickle\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_words(words, f):\n",
    "    for word in words:\n",
    "        word_str = [word.word]\n",
    "        if word.pos:\n",
    "            word_str.append(f\"/{word.pos}/\")\n",
    "        if word.topic:\n",
    "            word_str.append(f\"[{word.topic}]\")\n",
    "        print(\" \".join(word_str), file=f)\n",
    "        print(f\"\\t{word.definition}{' |n| ' if word.example is None else ''}\", file=f)\n",
    "        if word.example:\n",
    "            print(f\"\\t\\\"{word.example}\\\"{' |e|' if word.from_example_expansion else ''}\", file=f)\n",
    "\n",
    "        print(\"\", file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 23:37:24 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2020-04-28 23:37:24 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-04-28 23:37:24 INFO: Use device: gpu\n",
      "2020-04-28 23:37:24 INFO: Loading: tokenize\n",
      "2020-04-28 23:37:24 INFO: Loading: pos\n",
      "2020-04-28 23:37:25 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'VBD': 3, 'NNP': 0, 'VBN': 0, 'IN': 0, 'POS': 0, 'NN': 0, '.': 0, 'PRP': 0, 'CD': 0, 'CC': 0, 'VBZ': 0})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'VBD'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 23:56:07 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2020-04-30 23:56:07 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-04-30 23:56:07 INFO: Use device: gpu\n",
      "2020-04-30 23:56:07 INFO: Loading: tokenize\n",
      "2020-04-30 23:56:09 INFO: Loading: pos\n",
      "2020-04-30 23:56:10 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens(datasets.SpecialTokens.special_tokens_dict())\n",
    "blacklist = datasets.Blacklist.load(\"../data/blacklist.pickle\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"../models/inverse_en_dictionary_parsed_lr_00001/checkpoint-200000\").to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|bod|>the feeling of falling perpetually into the ground.<|bd|>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sickle-picker /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"a programmer hit a big white mark by repeatedly destroying source code within minutes of its release\"\n",
      "\n",
      "trivialist /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"his basic theorem proved that the vector space allows two int and two floats to be vectors and is fixed\"\n",
      "\n",
      "hard coded /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"the developer is a known hacker, and may be manually programmed to do the job\"\n",
      "\n",
      "cynogandist /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"the software can't read code that is designed to be gibberish\"\n",
      "\n",
      "nickwaggle /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"the hacker behind the hack is back as anickwagler\"\n",
      "\n",
      "bugcatcher /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"especially bugcatchers don't know how to write concise code\"\n",
      "\n",
      "neonad /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"the neonicad of R programming\"\n",
      "\n",
      "standard-dev /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"prices for the standard-dev versions of commodity semiconductor and advanced video components were much higher\"\n",
      "\n",
      "Xeroxer /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"when you need help on Xeroxers, fix them\"\n",
      "\n",
      "bludger /noun/ [Computing]\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"a bludger is most certainly a software developer, not a programming expert\"\n",
      "\n",
      "messingroid /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"one of many confused mess girls whose job it is to fix your coding mistakes\"\n",
      "\n",
      "rustcoder /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"a hack includes another vectorized transformation and a collision detection hackcore that simulate collisions with simple components\"\n",
      "\n",
      "stackfuck /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"stackfuck! You wrote that error!\"\n",
      "\n",
      "automoder /noun/\n",
      "\ta programmer who can't seem to figure out what is wrong with his code\n",
      "\t\"his automodel was partly a mistake\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "defn = \"a programmer who can't seem to figure out what is wrong with his code\"\n",
    "prefix = f\"{datasets.SpecialTokens.BOS_TOKEN}{defn}{datasets.SpecialTokens.DEFINITION_SEP}\"\n",
    "words, stats = datasets.InverseParsedDictionaryDefinitionDataset.generate_words(\n",
    "    tokenizer, model,\n",
    "    prefix=prefix,\n",
    "    num=100,\n",
    "    max_iterations=1, \n",
    "    blacklist=blacklist, \n",
    "    generation_args=dict(\n",
    "        top_k=500,\n",
    "        num_return_sequences=50,\n",
    "        max_length=256,\n",
    "        do_sample=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print_words(words, sys.stdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "company_makeup",
   "language": "python",
   "name": "company_makeup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
