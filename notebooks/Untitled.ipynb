{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 116kB [00:00, 13.1MB/s]                    \n",
      "2020-04-29 00:17:40 INFO: Downloading default packages for language: en (English)...\n",
      "2020-04-29 00:17:41 INFO: File exists: /home/tdimson/stanza_resources/en/default.zip.\n",
      "2020-04-29 00:17:44 INFO: Finished downloading models and saved to /home/tdimson/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import stanza\n",
    "from collections import Counter\n",
    "stanza.download('en')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import datasets\n",
    "import pickle\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_words(words, f):\n",
    "    for word in words:\n",
    "        word_str = [word.word]\n",
    "        if word.pos:\n",
    "            word_str.append(f\"/{word.pos}/\")\n",
    "        if word.topic:\n",
    "            word_str.append(f\"[{word.topic}]\")\n",
    "        print(\" \".join(word_str), file=f)\n",
    "        print(f\"\\t{word.definition}\", file=f)\n",
    "        print(f\"\\t\\\"{word.example}\\\"{' |e|' if word.from_example_expansion else ''}\", file=f)\n",
    "\n",
    "        print(\"\", file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-28 23:37:24 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2020-04-28 23:37:24 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-04-28 23:37:24 INFO: Use device: gpu\n",
      "2020-04-28 23:37:24 INFO: Loading: tokenize\n",
      "2020-04-28 23:37:24 INFO: Loading: pos\n",
      "2020-04-28 23:37:25 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'VBD': 3, 'NNP': 0, 'VBN': 0, 'IN': 0, 'POS': 0, 'NN': 0, '.': 0, 'PRP': 0, 'CD': 0, 'CC': 0, 'VBZ': 0})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'VBD'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-29 00:17:58 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2020-04-29 00:17:58 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-04-29 00:17:58 INFO: Use device: gpu\n",
      "2020-04-29 00:17:58 INFO: Loading: tokenize\n",
      "2020-04-29 00:17:59 INFO: Loading: pos\n",
      "2020-04-29 00:18:00 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens(datasets.SpecialTokens.special_tokens_dict())\n",
    "blacklist = set((x.lower() for x in itertools.chain.from_iterable(\n",
    "    [e.word] + e.derivatives\n",
    "    for e in pickle.load(open(f\"../data/en_dictionary_parsed_randomized.pickle\", \"rb\")))\n",
    "))\n",
    "model = AutoModelWithLMHead.from_pretrained(\"../models/en_dictionary_parsed_lr_00001/checkpoint-120000\").to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|bod|>dasfdagsmn24134fd.s~!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations=1 | items_considered 1.00@50, failed_match 0.00@0, blacklist_filtered 0.68@34, seen_filtered 0.00@0, proper_noun_filtered 0.08@4, example_filtered 0.00@0, example_expansions 0.20@10, example_expansion_success 0.14@7, returned 0.18@9\n",
      "\n",
      "dipeterallopyelia /noun/\n",
      "\tdimple dyes that color the eye with dewy- <|bd|> dipeterallopyelia esters\n",
      "\t\"the dipeterallopyelia coloration\" |e|\n",
      "\n",
      "reentry /noun/\n",
      "\tan admission or increase to one's financial liabilities arising from the reentry of property or goods\n",
      "\t\"a reentry of the board of directors\"\n",
      "\n",
      "lappurine /noun/ [historical]\n",
      "\ta small vessel with a narrow bottom and one or more sail pylons.\n",
      "\t\"a ferry that carried lappurine across the Thames\" |e|\n",
      "\n",
      "heptathione nephinium /noun/\n",
      "\ta bacterium related to heptaparum, closely related to E. coli, which causes yeast infection and can also cause dengue and other fever.\n",
      "\t\"a bacterium from Asia is the most common heptathione nephinium.\" |e|\n",
      "\n",
      "cobold /noun/\n",
      "\ta silver-crusted goldfish that lives in coastal waters and deposits deposits it as remains\n",
      "\t\"the new spawn of the cobold is an assemblage of chitinids\"\n",
      "\n",
      "shandies /plural noun/\n",
      "\ta storeroom.\n",
      "\t\"shandies were a great institution to live in\" |e|\n",
      "\n",
      "cyberpower /noun/\n",
      "\tthe mass produced or wielded by the collective power or means of the Internet.\n",
      "\t\"the widespread use of security measures is the cyberpower of our society\" |e|\n",
      "\n",
      "fibergum /noun/\n",
      "\ta mixture of fabrics made from fiber.\n",
      "\t\"a fibergum cotton dress\" |e|\n",
      "\n",
      "makari /noun/\n",
      "\ta type of Japanese salad, consisting of tomatoes chopped briskly and cooked (often sprinkled with mayonnaise)\n",
      "\t\"my sweet Makari chicken\" |e|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words, stats = datasets.ParsedDictionaryDefinitionDataset.generate_words(\n",
    "    tokenizer, model,\n",
    "    num=10,\n",
    "    max_iterations=1, \n",
    "    blacklist=blacklist, \n",
    "    do_example_expansion=True, \n",
    "    generation_args=dict(\n",
    "        top_k=300,\n",
    "        num_return_sequences=50,\n",
    "        max_length=256,\n",
    "        do_sample=True,\n",
    "    ),\n",
    "    expansion_generation_overrides=dict(\n",
    "        top_k=50,\n",
    "        num_return_sequences=20,\n",
    "        do_sample=True,\n",
    "    ),\n",
    "    num_expansion_candidates=20,\n",
    "    example_match_pos_pipeline=nlp,\n",
    ")\n",
    "\n",
    "print(stats)\n",
    "print()\n",
    "print_words(words, sys.stdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "company_makeup",
   "language": "python",
   "name": "company_makeup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
