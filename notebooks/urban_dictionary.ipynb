{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools \n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../title_maker_pro\")\n",
    "from title_maker_pro import datasets\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/mnt/evo/projects/title-maker-pro/data/urban_dictionary_words.pickle\"\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = datasets.Blacklist.load(\"/mnt/evo/projects/title-maker-pro/models/blacklist.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dataset = pd.DataFrame(\n",
    "    (\n",
    "        (d.word, d.meaning, d.examples[0], d.upvotes, d.downvotes, d.creation_epoch) \n",
    "        for d in itertools.chain.from_iterable(e.definitions for e in dataset.values())\n",
    "    ),\n",
    "    columns=[\"word\", \"meaning\", \"example\", \"upvotes\", \"downvotes\", \"creation_epoch\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(original, f, name):\n",
    "    n = original[f]\n",
    "    print(f\"{name} cut by {100 * len(n) / (len(original)):.2f}% ({len(original)} -> {len(n)})\")\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blacklist cut by 49.63% (2961824 -> 1469932)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tdimson/anaconda3/envs/company_makeup/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length cut by 65.20% (1469932 -> 958444)\n",
      "upvotes cut by 47.83% (958444 -> 458387)\n"
     ]
    }
   ],
   "source": [
    "t = pd_dataset.copy()\n",
    "t = cut(t, ~(pd_dataset[\"word\"].apply(blacklist.contains)), name=\"blacklist\")\n",
    "t = cut(t, ((pd_dataset[\"example\"].str.len() + pd_dataset[\"meaning\"].str.len() + pd_dataset[\"word\"].str.len()) < 250), name=\"length\")\n",
    "t = cut(t, (pd_dataset[\"upvotes\"] >= 4), name=\"upvotes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = OrderedDict()\n",
    "i = 0\n",
    "num_defns = 0\n",
    "for k, ud_word in dataset.items():\n",
    "    good_defns = []\n",
    "    for d in ud_word.definitions:\n",
    "        if i in valid_indexes:\n",
    "            good_defns.append(d)\n",
    "            num_defns += 1\n",
    "        i += 1\n",
    "    \n",
    "    if good_defns:\n",
    "        new = copy.deepcopy(ud_word)\n",
    "        new.definitions = good_defns\n",
    "        cleaned_dataset[k] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset_path = \"/mnt/evo/projects/title-maker-pro/data/urban_dictionary_250_cleaned.pickle\"\n",
    "with open(cleaned_dataset_path, \"wb\") as f:\n",
    "    pickle.dump(cleaned_dataset, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos', use)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens(datasets.SpecialTokens.special_tokens_dict())\n",
    "blacklist = datasets.Blacklist.load(\"/mnt/evo/projects/title-maker-pro/models/blacklist_urban_dictionary.pickle\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"/mnt/evo/projects/title-maker-pro/models/urban_dictionary_250_cleaned_lr_00005_b9_seed4/checkpoint-60000\").to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499332bf7a7b4a2daf1f3e3a16dcfb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words, stats = datasets.UrbanDictionaryDataset.generate_words(\n",
    "    tokenizer, model,\n",
    "    num=5,\n",
    "    max_iterations=5, \n",
    "    blacklist=blacklist, \n",
    "    generation_args=dict(\n",
    "        top_k=200,\n",
    "        num_return_sequences=5,\n",
    "        max_length=250,\n",
    "        do_sample=True,\n",
    "    ),\n",
    "    dedupe_titles=True,\n",
    "    filter_proper_nouns=True,\n",
    "    min_definition_words=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations=4 time=13.484499454498291 stanza_time=0.0 | items_considered 1.00@19, failed_match 0.53@10, blacklist_filtered 0.00@0, seen_filtered 0.00@0, proper_noun_filtered 0.11@2, example_missing 0.00@0, short_definitions 0.00@0, example_missing_title 0.11@2, example_pos_match_failed 0.00@0, user_filtered 0.00@0, returned 0.26@5\n",
      "\n",
      "sogdakapoo\n",
      "\tBasically a guy, pretty much man like. So basically... a girl, who, when she gets at the end of their contact line, says something\n",
      "\t\"Oh, my god, look! It's Sogdakapoo!\n",
      "\t \n",
      "\tHe used to be such a skank, 'cause he sucked all my dick and he called it his.\n",
      "\t \n",
      "\tIn the bad part on the break! I caught him snoring with his sack!\"\n",
      "----------------\n",
      "awesomsqueeblee\n",
      "4. The plural of awesomenessid very easily.\"d, or somthing like that.\n",
      "\t\"awesomsqueeblee-nawesomemephyteezomemephedamfukkie \n",
      "\twhen someone says something that is abresolutly awesome.\"\n",
      "----------------\n",
      "gifit\n",
      " Also can be used to describe the object in question. also can be used as an adjective.\n",
      "\t\"1. wow dont you just look a gifit today.\n",
      "\t2. This book is so faggotiff.\"\n",
      "----------------\n",
      "cumbyno-sucking-cowboy\n",
      "\tAn individual who is extremely cute, and dutiful.\n",
      "\t\"Baby Mo was watching me on the internet last night.  His girlfriend was such a cumbyno-sucking-cowboy!\"\n",
      "----------------\n",
      "gopsh\n",
      "\tsomething your ass looks like and sounds like gopsha ya hear?\n",
      "\t\"dude, i hate that guy\n",
      "\t\n",
      "\the's such a fkn boozer!\n",
      "\t\n",
      "\tyeah, he's a straight up Gopsh shite!\"\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(stats)\n",
    "print()\n",
    "datasets.GeneratedWord.print_words(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "company_makeup",
   "language": "python",
   "name": "company_makeup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
