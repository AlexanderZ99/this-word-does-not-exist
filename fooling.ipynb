{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urban_dictionary_scraper\n",
    "import torch\n",
    "import re\n",
    "import sys\n",
    "import pickle\n",
    "import wiki_article \n",
    "import dictionary_definition\n",
    "import glob\n",
    "import modeling\n",
    "import itertools\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from dataclasses import dataclass\n",
    "from io import StringIO\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from scipy import stats\n",
    "import hashlib\n",
    "from collections import OrderedDict\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoints(base_dir):\n",
    "    checkpoint_dirs = glob.glob(f\"{base_dir}/checkpoint*\")\n",
    "    checkpoint_dirs.sort(key=lambda x: int(x[(x.index(\"checkpoint-\") + len(\"checkpoint-\")):]))\n",
    "    return checkpoint_dirs\n",
    "modeling_gpt\n",
    "def evaluate_lm_checkpoints(base_dir, validation_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "    for d in get_checkpoints(base_dir):\n",
    "        model = AutoModelWithLMHead.from_pretrained(d).to('cuda')\n",
    "        refined_model_eval = wiki_article.lm_eval(model, tokenizer, validation_path)\n",
    "        print(f\"{d}: {refined_model_eval}\")\n",
    "tokenizer\n",
    "def evaluate_title_checkpoints(base_dir, validation_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")print(parsed_urban_dictionary_scraperpage.body.prettify())\n",
    "    for d in get_checkpoints(base_dir):\n",
    "        model = AutoModelWithLMHead.from_pretrained(d).to('cuda')\n",
    "        refined_model_eval = wiki_article.run_title_evaluation(model, tokenizer, validation_path)\n",
    "        print(f\"{d}: m={refined_model_eval.mean}, v={refined_model_eval.variance}\")\n",
    "\n",
    "# evaluate_lm_checkAutoModelWithLMHead, AutoTokenizer, points(\"models/wikitext_103_stride_512_v0/\", \"data/wikitext-103-title-train/wiki_title.valid.raw\")\n",
    "#print(glob.glob(\"models/wikitext_103_stride_512_v0/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/en_dictionary_parsed_randomized.pickle\", \"rb\") as f:\n",
    "    parsed_dictionary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_blacklist = set()\n",
    "for word in parsed_dictionary:\n",
    "    potential_blacklist.add(word.word)\n",
    "    potential_blacklist.update(word.derivatives)\n",
    "print(len(parsed_dictionary))\n",
    "print(len(potential_blacklist))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens(datasets.SpecialTokens.special_tokens_dict())\n",
    "args = SimpleNamespace()\n",
    "args.block_size = 768\n",
    "dataset = datasets.ParsedDictionaryDefinitionDataset(tokenizer, args, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_set = list(itertools.chain.from_iterable(dataset._make_examples(tokenizer, e) for e in parsed_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{len(flattened_set)} from {len(parsed_dictionary)} entries\")\n",
    "word = tokenizer.encode(\"vitellogenin\")\n",
    "print(tokenizer.decode(dataset.bos_token_ids  + [1] + dataset.eos_token_ids))\n",
    "print(tokenizer.decode(tokenizer.encode(\"<|bod|>\\\"<|eod|>\")))\n",
    "\n",
    "print(f\"\\\"{tokenizer.decode(dataset.pos_sep_ids)}\\\"\")\n",
    "tokenizer.decode(dataset._make_examples(tokenizer, parsed_dictionary[0])[0])\n",
    "# for example in random.choices(flattened_set, k=20):\n",
    "#     print(tokenizer.decode(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in dataset._make_examples(tokenizer, parsed_dictionary[10430]):\n",
    "    print(tokenizer.decode(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/all_words.pickle\", \"rb\") as f:\n",
    "    #words = pickle.load(f)\n",
    "    #items = list(words.items())\n",
    "    random.shuffle(items)\n",
    "    items = OrderedDict(items)\n",
    "    \n",
    "with open(\"data/all_words_randomized.pickle\", \"wb\") as f:\n",
    "    pickle.dump(items, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_dictionary_scraper.UrbanDictionaryDataset._make_examples(tokenizer, words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"gpt2\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrefined_model_eval = wiki_article.run_title_evaluation(urban_dictionary_scrapermodel, tokenizer, \"wikitext-103-raw/wiki.valid.raw\")\n",
    "unrefined_model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"output_103/\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_model_eval = wiki_article.run_title_evaluation(model, tokenizer, \"wikitext-103-raw/wiki.valid.raw\")\n",
    "refined_model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = f\"\\\"TITLE\\\" is a song collaboration by Chinese artist Pamela Chen and Canadian singer Thomas Dimson, first released independently in March 2020. After gaining popularity amongst the cat community, the single was re-released by major label Columbia Records in May 2020. Pamela describes the song as being originally inspired by her two kittens, Apollo and Bean who once said meow.<bot>\"\n",
    "\n",
    "model =  modeling.GPT2LMHeadWithWeightedLossModel.from_pretrained(\"models/wikitext-103-raw-title-scale-20-lr5e-5\").to(\"cuda\")\n",
    "input = tokenizer.encode(sequence, return_tensors=\"pt\").to('cuda')\n",
    "generated = model.generate(input, max_length=100, num_return_sequences=100, temperature=1)\n",
    "\n",
    "print(f\"Prompt text: {sequence}\")\n",
    "for i in range(generated.size()[0]):\n",
    "    sentence_tokens = generated[i, :].tolist()\n",
    "    decoded = tokenizer.decode(sentence_tokens)\n",
    "    m = re.search(r\"<bot>(.*?)<eot>\", decoded)\n",
    "    if m:urban_dictionary_scraper\n",
    "        print(f\"{i}) {m.groups(1)}\")\n",
    "    else:\n",
    "        print(f\"{i}) Didn't work\")\n",
    "    \n",
    "\n",
    "resulting_string = tokenizer.decode(generated.tolist()[0])\n",
    "# print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in entries: \n",
    "    m = re.match(r\"\\s*\" + re.escape(entry.title) + r\"\\d*\\s*(\\|[^|]*\\|)?\\s*\", entry.entry_str)\n",
    "    if m:\n",
    "        trainable_entry = entry.entry_str[m.span()[1]:].strip()\n",
    "        if not trainable_entry:\n",
    "            raise RuntimeError(f\"Bad entry for {entry.title}: '{entry.entry_str}'\")\n",
    "    else:\n",
    "        raise RuntimeError(f\"Couldn't match {entry.title} on '{entry.entry_str}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_path = \"data/com_apple_MobileAsset_DictionaryServices_dictionaryOSX/69b7ab1cf0f75ad16bf6662b0a77fbfd36b7941f.asset/AssetData/New Oxford American Dictionary.dictionary/Contents/Resources/Body.data\"\n",
    "with open(dictionary_path, \"rb\") as f:\n",
    "    valid_words = {e.title.upper() for e in dictionary_definition.DictionaryDefinition.gen_from_apple_dictionary(f)}full_dataset = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  modeling.GPT2LMHeadWithWeightedLossModel.from_pretrained(\"models/dictionary-scale-10-lr5e-5\").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = dictionary_definition.generate_words(\n",
    "    tokenizer, model, allow_proper_nouns=False, blacklist=valid_words, num=1000, max_iterations=40\n",
    ")\n",
    "words.sort(key=lambda x: x.title)\n",
    "for w in words:\n",
    "    print(f\"{w} {w.entry_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"words.tsv\", \"w\") as f:\n",
    "    for word in words:\n",
    "        f.write(f\"{word.title}\\t{word.entry_str}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens(datasets.SpecialTokens.special_tokens_dict())\n",
    "blacklist = set((x.lower() for x in itertools.chain.from_iterable(\n",
    "    [e.word] + e.derivatives\n",
    "    for e in pickle.load(open(f\"data/en_dictionary_parsed_randomized.pickle\", \"rb\")))\n",
    "))\n",
    "model = AutoModelWithLMHead.from_pretrained(\"models/en_dictionary_parsed_lr_00001/checkpoint-120000\").to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations=8 |items_considered 1.00@398, failed_match 0.01@4, blacklist_filtered 0.71@282, seen_filtered 0.00@0, example_filtered 0.00@0, example_expansions 0.25@99, example_expansion_success 0.22@87, returned 0.25@100\n",
      "ficatic /noun/\n",
      "\tan autobiography or short fiction.\n",
      "\t\"a widely read ficatic\" |e|\n",
      "\n",
      "Chiosi /noun/\n",
      "\tthe branch of scientific study that deals with electromagnetism.\n",
      "\t\"the philosophical and theological work is now also called Chiosi Geometry\" |e|\n",
      "\n",
      "parvane /noun/ [chiefly dated]\n",
      "\tthe outer membrane around the mouth of beef.\n",
      "\t\"tea makes use of parvane\" |e|\n",
      "\n",
      "tumble-doodle /noun/\n",
      "\ta thing that is easy to leap over or that is difficult to do otherwise\n",
      "\t\"the elephant has really gotta be the tumble-doodle for it to work\"\n",
      "\n",
      "teridifiable /adjective/\n",
      "\teasily identified.\n",
      "\t\"teridifiable data from commercial databases\" |e|\n",
      "\n",
      "toh /exclamation/\n",
      "\tthe nailing of a ball, racket, or other object on a surface.\n",
      "\t\"“OK! Toh! My ball!”\" |e|\n",
      "\n",
      "salutory /adjective/ [Law]\n",
      "\t(of money, documents, papers, etc.) to be paid to an officer in relation to a disposition of a lawsuit, case, etc.\n",
      "\t\"salutory damages of up to $10,000\" |e|\n",
      "\n",
      "bunbun /adjective/\n",
      "\t(of a person) solemn and slow- tempering\n",
      "\t\"unemployed bunbun, going down at night\" |e|\n",
      "\n",
      "preperation /noun/\n",
      "\ta slight reduction in the quantity of a particular substance\n",
      "\t\"the reduction in weight in women followed a gradual deterioration in preperation\" |e|\n",
      "\n",
      "dramefoil /abbreviation/\n",
      "\tdrama.\n",
      "\t\"The Lord's Resort desultory, featuring a dramefoil\" |e|\n",
      "\n",
      "dead-on /adjective [attributive]/\n",
      "\ttransparent and untainted\n",
      "\t\"a dead-on movie project\"\n",
      "\n",
      "unhypnotic /adjective/\n",
      "\tnot having or expressing deep hypnosis.\n",
      "\t\"an unhypnotic method\" |e|\n",
      "\n",
      "stupefied /adjective/\n",
      "\thaving experienced shock or horror\n",
      "\t\"stupefied crowds\" |e|\n",
      "\n",
      "semicolonize /verb [with object]/ [archaic]\n",
      "\tmake one atomless by decomposition.\n",
      "\t\"I who are rich and petty, semicolonize society with a kind of wealth\" |e|\n",
      "\n",
      "cotton-cultivation /noun/\n",
      "\ta form of noncultivation of cotton, especially of the cotton plant (Geniconia longomium).\n",
      "\t\"cotton-cultivation may be a serious threat to rural economies\" |e|\n",
      "\n",
      "pennig /noun/\n",
      "\ta thing whose outer surface is a peat berry or other plant with an earthy shell.\n",
      "\t\"carlsing, pennig berries\" |e|\n",
      "\n",
      "nurserywoman /noun/\n",
      "\ta caring nurse or caretaker employed to provide a home or health care to people who are sick or elderly.\n",
      "\t\"they're expected to fill the nurserywoman's position, which is mainly to do domestic duties\" |e|\n",
      "\n",
      "perceiving /noun/\n",
      "\tthe state of being concerned with or guided by\n",
      "\t\"my experiences from my time as a Perceiving Highlander\"\n",
      "\n",
      "proverbography /noun/\n",
      "\ttextual or structural argument on the supposition of an aim or purpose from the standpoint of specific argument or action\n",
      "\t\"proverbography of the Bible\" |e|\n",
      "\n",
      "soupless /adjective/\n",
      "\tfull and plentiful; abundant\n",
      "\t\"his soupless enthusiasm\"\n",
      "\n",
      "minimando /noun/\n",
      "\ta salsa with vermouth and lime juice with chocolate and sugar added, and often served either cold, hot, or in a can.\n",
      "\t\"do us a favor and join a few of them in minimando\" |e|\n",
      "\n",
      "bronchosphere /noun/\n",
      "\tthe upper layer of the boundary layer between the warm ocean and the North Pacific Ocean, or between the oceanic crust and the continental shelf in the crustal belts.\n",
      "\t\"the northern ocean may contain the bronchosphere\" |e|\n",
      "\n",
      "Olivata\n",
      "\ta city in northwestern Italy, in the north central part of the country; county town, Livorno. It is a picturesque palace center and a major industrial city; population 310,900 (est. 2007).\n",
      "\t\"Olivata Opera House\" |e|\n",
      "\n",
      "sabat /verb [with object]/\n",
      "\tforce (someone) to do or become incommunicado\n",
      "\t\"he was asSabata, always abatted\" |e|\n",
      "\n",
      "viment /noun/\n",
      "\tpure resin extracted from plants or flowers from dry dates.\n",
      "\t\"viment paste\" |e|\n",
      "\n",
      "hobartine /noun/\n",
      "\ta redish-yellow worm that typically bears spikes of glandular threadlike white or yellow flowers which protrude on the top and under the skin.\n",
      "\t\"a Hobartine worm\" |e|\n",
      "\n",
      "alpinism /noun/\n",
      "\tthe splitting of two or more groups of elements like trees, rocks, or continents into fragments or agglutinous masses under concentrated pressure.\n",
      "\t\"the local origins of modern alpinism\" |e|\n",
      "\n",
      "blackbelt /noun/\n",
      "\ta black belt of elite military discipline, especially an officer of the khaki or bikin stripe.\n",
      "\t\"a colonel in the Blackbelt Corps <|bto|> many believe that the blackbelt role will help the US expand against the South\" |e|\n",
      "\n",
      "tandoorya /noun/\n",
      "\ta dish consisting of potatoes and vegetables cooked in oil with baked oil left until thickened.\n",
      "\t\"don't put them in the fridge until the kids get to do ten minutes of dining in a Tandoorya\" |e|\n",
      "\n",
      "chicadillo /noun/\n",
      "\ta large narrow-bodied plant of tropical America, with large pearly bright wings and a cylindrical petaled back, native to the Italian city of Puebla in Mexico.\n",
      "\t\"the chicadillo is tough to kill through seed line, little or no fodder, and often doesn't require proper irrigation\" |e|\n",
      "\n",
      "acchitecture /noun/\n",
      "\ta design or construction design.\n",
      "\t\"acchitecture plays a significant role in the building philosophy of the City of New York\" |e|\n",
      "\n",
      "nonconstructive /adjective/\n",
      "\taffecting nothing but a single step; unpolished\n",
      "\t\"nonconstructive methods\"\n",
      "\n",
      "high-quality /adjective/\n",
      "\tof great quality; outstanding\n",
      "\t\"a high-quality collection inspired by the local culture\"\n",
      "\n",
      "Lilak /adjective/ [informal]\n",
      "\t(of a person's eyes) red.\n",
      "\t\"Lilak look at her through lilac eyes\" |e|\n",
      "\n",
      "dineout /noun/\n",
      "\ta menu where customers are allowed to order coffee and soda from a specially equipped stand or at a place of entertainment.\n",
      "\t\"dineout deals\" |e|\n",
      "\n",
      "piss-piss /noun/\n",
      "\ta state of unhappiness.\n",
      "\t\"I'm definitely on the point of tears, piss-piss\" |e|\n",
      "\n",
      "Rathraffian River\n",
      "\tan open valley running parallel with the Atlantic coast of Greece and linking the Bosphorus Stream to Turkey.\n",
      "\t\"the Bosphorus flows into the Red Sea to form the Rathraffian River\" |e|\n",
      "\n",
      "h.m. /abbreviation/\n",
      "\thour or minute\n",
      "\t\"he agreed to travel with us for a few h.m., until midnight\" |e|\n",
      "\n",
      "Coyola Hills\n",
      "\ta city in southern California, southeast of Los Angeles; population 55,761 (est. 2008).\n",
      "\t\"Coyola Hills is nestled among rock and clay mountains in Southern California\" |e|\n",
      "\n",
      "presure /verb [with object]/\n",
      "\t(of a tooth or other part) catch or become firmly fixed as a mark by removal or sealing\n",
      "\t\"presured teeth\" |e|\n",
      "\n",
      "penicilliary /adjective/\n",
      "\trelating to the penicilliary system\n",
      "\t\"penicilliary disease\" |e|\n",
      "\n",
      "geometryal /adjective/\n",
      "\trelating to geometry or to physical phenomena.\n",
      "\t\"geometryal phenomena\" |e|\n",
      "\n",
      "cabanda /noun/\n",
      "\ta camango plant of the mint family that has fine leaves and fragrant tubular flowers, common throughout the Venezuelan and Central American rainforests.\n",
      "\t\"a cabanda plant\" |e|\n",
      "\n",
      "double-tweet /noun/\n",
      "\ta user's distinctive voice, typically one that allows them to share multiple posts as a single click or as a single link\n",
      "\t\"she's not exactly the kind of guy who throws parties with double-tweeters\" |e|\n",
      "\n",
      "detrend /noun/\n",
      "\tthe state of being turned inward and away from the center for inward movement\n",
      "\t\"the guilty party is scheduled to face detrends in the dock\" |e|\n",
      "\n",
      "overfaction /noun/\n",
      "\tthe tendency to create or combine a complex situation or state for one's own advantage.\n",
      "\t\"the overfaction surrounding her marriage\" |e|\n",
      "\n",
      "duckbird /noun/ [informal]\n",
      "\ta burrowing burrowing bird of a class that includes the buckshot-throated hawk, sawbill, grouse-lever, wading duck, tamed cichlid, and hookbird.\n",
      "\t\"the duckbird was a social and active bird in the early 1900s\" |e|\n",
      "\n",
      "taffunt /verb [with object]/\n",
      "\tpaint with taffunt\n",
      "\t\"taffunt curves in a tight ponytail\" |e|\n",
      "\n",
      "Lizela\n",
      "\tthe goddess, source of the rain, mother of the rain (now), and mother of the night; she is the celestial daughter of Pisces and Cepheus and of the fire of the underworld.\n",
      "\t\"a star with anodiacal sign “Lizela,” sits on the highest stage in the planetarium of Saturn\" |e|\n",
      "\n",
      "café /noun/\n",
      "\tan area of heated ale or cider.\n",
      "\t\"café from much wine\" |e|\n",
      "\n",
      "leamy /adjective/\n",
      "\t(of trees and plants) dense of sap; evergreen\n",
      "\t\"the house smell like leamy autumn leaves\" |e|\n",
      "\n",
      "c.c. /abbreviation/\n",
      "\tcatholic.\n",
      "\t\"the calcium levels are higher in the early c.c. than in the later c.c.\" |e|\n",
      "\n",
      "white-flowered /adjective/\n",
      "\tof or like a white flower.\n",
      "\t\"white-flowered cedar trees\" |e|\n",
      "\n",
      "pagglet /noun/\n",
      "\ta raised-pit breed of hen.\n",
      "\t\"the spars are breeding at Panthera National Park in Austria with a pagglet\" |e|\n",
      "\n",
      "antennaean /noun/\n",
      "\tthe earliest age of the human papyrus.\n",
      "\t\"Clement the Elder spent the Roman EmpireAntennaean to put the finishing touches on the manuscript\" |e|\n",
      "\n",
      "prashnake /verb [no object]/\n",
      "\ttouch an onion with the prashnake.\n",
      "\t\"her cheeks were prashnaked with fear\" |e|\n",
      "\n",
      "substanthalene /noun/\n",
      "\ta synthetic synthetic resin of subthalene, derived from resins olivine and used as an oil in perfumes.\n",
      "\t\"substanthalene bottles\" |e|\n",
      "\n",
      "Grosvenor II\n",
      "\t(circa his twenty-third birthday), brother of Henry VI and grandson of Henry VII.\n",
      "\t\"Grosvenor II was born his death in 1426\" |e|\n",
      "\n",
      "Jershus\n",
      "\ta satellite of the Jupiter-Saturnian system that is thought to have cooled Saturn at about V–J 10.6 million years ago.\n",
      "\t\"Jershus has a five-mile (7.3 km) wide reddish–blue disk that orbits the sun's disk at greater angles to that of the Sun's surface\" |e|\n",
      "\n",
      "cormobranch /noun/\n",
      "\tcoil or cylinder shaped like a corm of a worm, especially in a lab.\n",
      "\t\"the bell with the end of a cormobranch is called the worm bell.\" |e|\n",
      "\n",
      "joomar /noun/\n",
      "\ta stupid or stupid-looking person.\n",
      "\t\"I am no joomar!\" |e|\n",
      "\n",
      "carolyn /noun/\n",
      "\t(in western Canada) a tall, vigorous lily; a cat.\n",
      "\t\"Carolyn watched her mother, soaking in the morning sun\" |e|\n",
      "\n",
      "unstinkably /adverb/\n",
      "\twith good effect; easily\n",
      "\t\"this concert is unstinkably good\" |e|\n",
      "\n",
      "patrone /noun/\n",
      "\ta white or reddish mineral occurring inside a pigment containing disodium phosphate, consisting of bronze oxide or silver.\n",
      "\t\"a pair of blue patrone armor\" |e|\n",
      "\n",
      "cantonize /verb [with object]/\n",
      "\tacquire the same property or privileges as every other member of a larger group of citizens.\n",
      "\t\"that entire economic system was cantonized by trade\" |e|\n",
      "\n",
      "bafetida /noun/\n",
      "\tdramatized or animated animation in which the characters are painted with decoration, typically along the lines of traditional character designs.\n",
      "\t\"the cartoon style of the bafetida is a vibrant phenomenon\" |e|\n",
      "\n",
      "contribuero /noun/\n",
      "\ta woman living in a rural settlement.\n",
      "\t\"the first Contribuero left to settle down in Minnesota on an illegal tourist\" |e|\n",
      "\n",
      "minearn /verb [with object]/\n",
      "\timmediately begin making or making a limited statement, especially in order to avoid controversy or be asked to repeat another statement\n",
      "\t\"the company has been minearning stocks in the UK\"\n",
      "\n",
      "post-earth /adjective/\n",
      "\trelating to the past or during the time of the earth, especially after the earth was deceded, inhabited, or inhabited\n",
      "\t\"this post-earth civilization\"\n",
      "\n",
      "Ibragim el-Bahari\n",
      "\ta resort town in southeastern Jordan, an oil port in southern January.\n",
      "\t\"Ibragim el-Bahari is a key center along the Jordan River\" |e|\n",
      "\n",
      "smore-proof /noun/\n",
      "\tthe surface material of a tooth\n",
      "\t\"a layer of smore-proof ice cream\" |e|\n",
      "\n",
      "pahrenheit /noun/\n",
      "\ttemperature equal to 27°F.\n",
      "\t\"a pahrenheit kiln\" |e|\n",
      "\n",
      "Sicandrea /adjective/\n",
      "\trelating to Sicily or its inhabitants.\n",
      "\t\"the language's own distinctive Sicandrea\" |e|\n",
      "\n",
      "second-rank /verb [with object]/\n",
      "\tget (someone or something) ahead of (someone or something else)\n",
      "\t\"he was second-ranking in rank at the high school\"\n",
      "\n",
      "vermouthcranoise /adjective/\n",
      "\tsickly, vomiting-like, and often inflamed.\n",
      "\t\"vermouthcranoises have become a common pathogen\" |e|\n",
      "\n",
      "salpitation /noun/\n",
      "\tan act of saluting.\n",
      "\t\"the wedding itself was held on salpitations\" |e|\n",
      "\n",
      "futurama /noun/\n",
      "\ta very short or slow speech.\n",
      "\t\"he started, talking about what was the futurama of television talk\" |e|\n",
      "\n",
      "bewildered /adjective/ [literary]\n",
      "\t(of a boat) low enough to abrade the boat by its sides by passing something about it.\n",
      "\t\"a boat in bewildered straits\" |e|\n",
      "\n",
      "Omnese /adjective/\n",
      "\trelating to Nigeria or its people or language.\n",
      "\t\"Omnese children are noted for their devotion to their elders\" |e|\n",
      "\n",
      "Cividae /plural noun/\n",
      "\tthe family Bifidae, including those related to the spiny dragonfly.\n",
      "\t\"the carvings of giant carvings of the Cividae\" |e|\n",
      "\n",
      "confidencial /adjective/\n",
      "\tof or like a confidencial.\n",
      "\t\"a confidencial court\" |e|\n",
      "\n",
      "glulose /adjective/\n",
      "\trelating to sugar or its compounds\n",
      "\t\"glulose-free chocolate\"\n",
      "\n",
      "mulef /noun/\n",
      "\ta woman's garment made of strong material, typically between one and three inches across at the shoulder.\n",
      "\t\"a mulef silk cover\" |e|\n",
      "\n",
      "drago /noun/\n",
      "\ta military or political force ranking above regiments in one's regiment or army.\n",
      "\t\"the drago is usually more powerful than itsimental brothers in battle\" |e|\n",
      "\n",
      "mixed-price /adjective/\n",
      "\tdenoting goods and services priced differently and run from one store in a particular country or region than in another\n",
      "\t\"a mixed-price flatware shop\"\n",
      "\n",
      "Borga River\n",
      "\ta river in central Hungary that rises in the Merovingian Mountains at the junction with the Dnieper in Hungary. The headwaters are located smack dab in front of the national capital of Hungary.\n",
      "\t\"in Budapest there are several caves in the Borga River\" |e|\n",
      "\n",
      "furbelink /verb [with object]/\n",
      "\tshorten or lengthen\n",
      "\t\"you need to furbelink your library Library\" |e|\n",
      "\n",
      "dopest /verb [with object]/\n",
      "\tfit up (a person or their body) very snugly\n",
      "\t\"tired of knocking on the kitchen door? And if you'd rather just dopest it up?\" |e|\n",
      "\n",
      "post-election /adjective/\n",
      "\tof or denoting the aftermath of a election\n",
      "\t\"a post-election survey\"\n",
      "\n",
      "repainboard /noun/\n",
      "\ta board or piece of steel placed on to a rebuilt ship for repainting.\n",
      "\t\"an earthquake-reduction repainboard\" |e|\n",
      "\n",
      "beaded /adjective/\n",
      "\tcovered or overlapping; nearly so\n",
      "\t\"I was crestfallen in a more beaded and congested street\" |e|\n",
      "\n",
      "colab /noun/\n",
      "\tan official portrait or other drawing of a person on another person's behalf.\n",
      "\t\"his colab was an overcoat with a red collar\" |e|\n",
      "\n",
      "columbarium-rotten /adjective/\n",
      "\t(of a living organism or part of a plant) eating itself or receiving food as another body part, typically from the gut\n",
      "\t\"columbarium-rotten birds\"\n",
      "\n",
      "Titus Christi\n",
      "\t(c. 1329–42), Roman general from East Africa; chief of the Tiberius Guard, 1387–42. A commander on arms against Rome and the Cenian Civil War, he fought against the invading Carthaginians, then Italy, under the pretenders. A Tetrarch, though much damaged by blows, he succeeded as emperor and made advances in Asia Minor, from which he was celebrated at Pompeii.\n",
      "\t\"Titus Christi led the army against the North (1013–73), which, in 1387, was crushed by the Carthaginians, he then founded Rome\" |e|\n",
      "\n",
      "carpetwork /noun/\n",
      "\tthe natural movement of snow by the side of the branches with or at its natural angles.\n",
      "\t\"carpets will start moving slowly as people keep in a carpetwork\" |e|\n",
      "\n",
      "recreating /adjective/ [Music]\n",
      "\tused in similes to express rhythmic rhythm or using a controlled movement of fingers or keys.\n",
      "\t\"by recreating Mozart's works, but using different kinds of notation\" |e|\n",
      "\n",
      "decitamin /noun/\n",
      "\ta soluble form of a group of vitamin which is essential as a preventative or in the treatment of anemia or blood pressure.\n",
      "\t\"decitamin B12\" |e|\n",
      "\n",
      "leaguewide /adjective/\n",
      "\t(of someone, their profession, or place of work) unfashionable and unaccepting.\n",
      "\t\"a leaguewide dean\" |e|\n",
      "\n",
      "Sotelo\n",
      "\tused with preceding letter or numeral to designate an ancient or medieval town or city in northern Latin America.\n",
      "\t\"a city in Sotelo's hills\" |e|\n",
      "\n",
      "chokepoint /noun/\n",
      "\ta pin or similar device used to cause detonation in a bomb, which detonates one can under pressure.\n",
      "\t\"the US detonated its first nuclear-capable bomb in 1945 with this small chokepoint off its coast\" |e|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words, stats = datasets.ParsedDictionaryDefinitionDataset.generate_words(\n",
    "    tokenizer, model, max_iterations=10, blacklist=blacklist, do_example_expansion=True, top_k=300, filter_proper_nouns=True,\n",
    ")\n",
    "\n",
    "print(stats)\n",
    "\n",
    "for word in words:\n",
    "    word_str = [word.word]\n",
    "    if word.pos:\n",
    "        word_str.append(f\"/{word.pos}/\")\n",
    "    if word.topic:\n",
    "        word_str.append(f\"[{word.topic}]\")\n",
    "    print(\" \".join(word_str))\n",
    "    print(f\"\\t{word.definition}\")\n",
    "    print(f\"\\t\\\"{word.example}\\\"{' |e|' if word.from_example_expansion else ''}\")\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from datasets import SpecialTokens\n",
    "\"\"\"\n",
    "input_str = f\"{tokenizer.bos_token}\"\n",
    "input_str = \"<|bod|>corner<|pos|>noun<|bd|>a point or space in a hierarchy that is within the order to which it moves along the axis.<|eod|>\"\n",
    "input = tokenizer.encode(input_str, return_tensors=\"pt\").to(\"cuda\")\n",
    "max_length = 512\n",
    "\n",
    "generated = model.generate(\n",
    "    input_ids=input, \n",
    "    max_length=max_length, \n",
    "    num_return_sequences=5, \n",
    "    temperature=1.0,\n",
    "    top_k=1000,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_ids=tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    ")\n",
    "\n",
    "break_specials = [\n",
    "    SpecialTokens.BOS_TOKEN, SpecialTokens.EOS_TOKEN, SpecialTokens.DEFINITION_SEP,\n",
    "    SpecialTokens.EXAMPLE_SEP, SpecialTokens.TOPIC_SEP, SpecialTokens.POS_SEP \n",
    "]\n",
    "break_special_ids = [tokenizer.encode(e, add_prefix_space=False)[0] for e in break_specials]\n",
    "break_special_token_map = {s: i for s, i in zip(break_specials, break_special_ids)}\n",
    "\n",
    "\n",
    "for i in range(generated.size()[0]):\n",
    "    sentence_tokens = generated[i, :].tolist()\n",
    "    \n",
    "    \n",
    "    accum = []\n",
    "    last_special = None\n",
    "    sep_map = {}\n",
    "    for token_id in sentence_tokens:\n",
    "        if token_id in break_special_ids:\n",
    "            if last_special is not None:\n",
    "                sep_map[last_special] = accum\n",
    "                accum = []\n",
    "                last_special = token_id\n",
    "            else:\n",
    "                last_special = token_id\n",
    "        else:\n",
    "            accum.append(token_id)\n",
    "            \n",
    "    sep_map[last_special] = accum\n",
    "    accum = []\n",
    "    \n",
    "    decode_sep_map = {\n",
    "        tokenizer.decode([k]): tokenizer.decode(v) for k, v in sep_map.items()\n",
    "    }\n",
    "        \n",
    "    print(decode_sep_map)\n",
    "    \n",
    "    # decoded = tokenizer.decode([e for e in sentence_tokens if e != tokenizer.pad_token_id])\n",
    "    print(decoded)  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"a bc\", add_prefix_space=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = set(e.title for e in pickle.load(open(\"data/all_words.pickle\", \"rb\")).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  modeling.GPT2LMHeadWithWeightedLossModel.from_pretrained(\n",
    "    \"models/urban_dictionary_cleaned_top_def_mu02_lr_0_000005_tw40\"\n",
    ").to(\"cuda\")\n",
    "tw40_words = urban_dictionary_scraper.generate_words(\n",
    "    tokenizer,\n",
    "    model,\n",
    "    blacklist=blacklist,\n",
    "    num=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tw1_words, open(\"data/labeling/tw1_words.pickle\", \"wb\"), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(tw40_words, open(\"data/labeling/tw40_words.pickle\", \"wb\"), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        (\n",
    "            word.word,\n",
    "            word.definition,\n",
    "            word.example.replace(,\n",
    "            \"tw1\" if i < len(tw1_words) else \"tw2\",\n",
    "        )\n",
    "        for i, word in enumerate(itertools.chain(\n",
    "            tw1_words,\n",
    "            tw40_words\n",
    "        ))\n",
    "    ],\n",
    "    columns=(\"word\", \"definition\", \"example\", \"dataset\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_no_dataset = sample[:]\n",
    "sample_no_dataset.to_csv(\"fun.csv\", index=False, columns=[\"word\", \"definition\", \"example\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens(datasets.SpecialTokens.special_tokens_dict())\n",
    "model =  AutoModelWithLMHead.from_pretrained(\"models/en_dictionary_parsed_lr_00005/checkpoint-50000\").to(\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
