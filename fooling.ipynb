{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urban_dictionary_scraper\n",
    "import torch\n",
    "import re\n",
    "import sys\n",
    "import pickle\n",
    "import wiki_article \n",
    "import dictionary_definition\n",
    "import glob\n",
    "import modeling\n",
    "import itertools\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from dataclasses import dataclass\n",
    "from io import StringIO\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from scipy import stats\n",
    "import hashlib\n",
    "from collections import OrderedDict\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoints(base_dir):\n",
    "    checkpoint_dirs = glob.glob(f\"{base_dir}/checkpoint*\")\n",
    "    checkpoint_dirs.sort(key=lambda x: int(x[(x.index(\"checkpoint-\") + len(\"checkpoint-\")):]))\n",
    "    return checkpoint_dirs\n",
    "modeling_gpt\n",
    "def evaluate_lm_checkpoints(base_dir, validation_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "    for d in get_checkpoints(base_dir):\n",
    "        model = AutoModelWithLMHead.from_pretrained(d).to('cuda')\n",
    "        refined_model_eval = wiki_article.lm_eval(model, tokenizer, validation_path)\n",
    "        print(f\"{d}: {refined_model_eval}\")\n",
    "tokenizer\n",
    "def evaluate_title_checkpoints(base_dir, validation_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")print(parsed_urban_dictionary_scraperpage.body.prettify())\n",
    "    for d in get_checkpoints(base_dir):\n",
    "        model = AutoModelWithLMHead.from_pretrained(d).to('cuda')\n",
    "        refined_model_eval = wiki_article.run_title_evaluation(model, tokenizer, validation_path)\n",
    "        print(f\"{d}: m={refined_model_eval.mean}, v={refined_model_eval.variance}\")\n",
    "\n",
    "# evaluate_lm_checkAutoModelWithLMHead, AutoTokenizer, points(\"models/wikitext_103_stride_512_v0/\", \"data/wikitext-103-title-train/wiki_title.valid.raw\")\n",
    "#print(glob.glob(\"models/wikitext_103_stride_512_v0/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/en_dictionary_parsed_randomized.pickle\", \"rb\") as f:\n",
    "    parsed_dictionary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98388\n",
      "114909\n"
     ]
    }
   ],
   "source": [
    "potential_blacklist = set()\n",
    "for word in parsed_dictionary:\n",
    "    potential_blacklist.add(word.word)\n",
    "    potential_blacklist.update(word.derivatives)\n",
    "print(len(parsed_dictionary))\n",
    "print(len(potential_blacklist))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens(datasets.SpecialTokens.special_tokens_dict())\n",
    "args = SimpleNamespace()\n",
    "args.block_size = 768\n",
    "dataset = datasets.ParsedDictionaryDefinitionDataset(tokenizer, args, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_set = list(itertools.chain.from_iterable(dataset._make_examples(tokenizer, e) for e in parsed_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|bod|> \" <|eod|>\n",
      "<|bod|> \" <|eod|>\n",
      "\"<|pos|>\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|bod|> vitellogenin <|eod|>'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(f\"{len(flattened_set)} from {len(parsed_dictionary)} entries\")\n",
    "word = tokenizer.encode(\"vitellogenin\")\n",
    "print(tokenizer.decode(dataset.bos_token_ids  + [1] + dataset.eos_token_ids))\n",
    "print(tokenizer.decode(tokenizer.encode(\"<|bod|>\\\"<|eod|>\")))\n",
    "\n",
    "print(f\"\\\"{tokenizer.decode(dataset.pos_sep_ids)}\\\"\")\n",
    "tokenizer.decode(dataset._make_examples(tokenizer, parsed_dictionary[0])[0])\n",
    "# for example in random.choices(flattened_set, k=20):\n",
    "#     print(tokenizer.decode(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167044 from 98388 entries\n",
      "<|bod|> Garuda <|bd|> an eaglelike being that Vishnu rides as his mount. <|eod|>\n",
      "<|bod|> off-screen <|pos|> adverb <|bd|> in real life rather than fictionally in a movie or on television <|be|> happy endings rarely happen off-screen <|eod|>\n",
      "<|bod|> kt. <|pos|> abbreviation <|bd|> knot(s) <|be|> a cruising speed of 240 kt <|eod|>\n",
      "<|bod|> notice <|pos|> noun <|bd|> notification or warning of something, especially to allow preparations to be made <|be|> interest rates are subject to fluctuation without notice <|eod|>\n",
      "<|bod|> rally <|pos|> verb <|bd|> (in tennis and other racket sports) engage in a rally. <|eod|>\n",
      "<|bod|> deuced <|pos|> adjective [attributive] <|bd|> used for emphasis, especially to express disapproval or frustration <|be|> I'm so deuced fond of you <|be|> I know it's deuced awkward for you <|eod|>\n",
      "<|bod|> Masuria <|bd|> a low-lying forested region in northeastern Poland. Formerly part of East Prussia, it was assigned to Poland after World War II. Also called Masurian Lakes. <|eod|>\n",
      "<|bod|> steep <|pos|> verb <|bd|> soak or saturate (cloth) in water or other liquid. <|eod|>\n",
      "<|bod|> valuable consideration <|pos|> noun <|bd|> legal consideration having some economic value, which is necessary for a contract to be enforceable. <|eod|>\n",
      "<|bod|> apolune <|pos|> noun <|bd|> the point at which a spacecraft in lunar orbit is furthest from the moon. <|eod|>\n",
      "<|bod|> EBITDA <|pos|> abbreviation <|bd|> earnings before interest, taxes, depreciation, and amortization (used as an indicator of the overall profitability of a business). <|eod|>\n",
      "<|bod|> tallboy <|pos|> noun <|bto|> North American <|bd|> a large can in which beer or another drink is sold, typically holding 16 or 25 fluid ounces <|be|> I was drinking a tallboy of Budweiser at the time <|eod|>\n",
      "<|bod|> Hiligaynon <|pos|> noun <|bd|> a member of a people inhabiting Panay, Negros, and other islands in the central Philippines. <|eod|>\n",
      "<|bod|> dark <|pos|> noun <|bd|> the absence of light in a place <|be|> Carolyn was sitting in the dark <|be|> he's scared of the dark <|eod|>\n",
      "<|bod|> emmet <|pos|> noun <|bd|> an ant. <|eod|>\n",
      "<|bod|> chain drive <|pos|> noun <|bd|> a mechanism in which power is transmitted from an engine to the wheels of a vehicle or a boat's propeller by means of a moving endless chain. <|eod|>\n",
      "<|bod|> ovary <|pos|> noun <|bd|> a female reproductive organ in which ova or eggs are produced, present in humans and other vertebrates as a pair. <|eod|>\n",
      "<|bod|> disjunct <|pos|> noun <|bto|> Logic <|bd|> each of the terms of a disjunctive proposition. <|eod|>\n",
      "<|bod|> groin <|pos|> noun <|bto|> Architecture <|bd|> a curved edge formed by two intersecting vaults. <|eod|>\n",
      "<|bod|> veneer <|pos|> noun <|bd|> a layer of wood used to make plywood. <|eod|>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|bod|> wallpaper <|pos|> noun <|bd|> paper that is pasted in vertical strips over the walls of a room to provide a decorative or textured surface. <|eod|>\n",
      "<|bod|> wallpaper <|pos|> noun <|bd|> an optional background pattern or picture on a computer or mobile phone screen. <|eod|>\n",
      "<|bod|> wallpaper <|pos|> verb [with object] <|bd|> apply wallpaper to (a wall or room). <|eod|>\n"
     ]
    }
   ],
   "source": [
    "for example in dataset._make_examples(tokenizer, parsed_dictionary[10430]):\n",
    "    print(tokenizer.decode(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/all_words.pickle\", \"rb\") as f:\n",
    "    #words = pickle.load(f)\n",
    "    #items = list(words.items())\n",
    "    random.shuffle(items)\n",
    "    items = OrderedDict(items)\n",
    "    \n",
    "with open(\"data/all_words_randomized.pickle\", \"wb\") as f:\n",
    "    pickle.dump(items, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_dictionary_scraper.UrbanDictionaryDataset._make_examples(tokenizer, words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"gpt2\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrefined_model_eval = wiki_article.run_title_evaluation(urban_dictionary_scrapermodel, tokenizer, \"wikitext-103-raw/wiki.valid.raw\")\n",
    "unrefined_model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"output_103/\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_model_eval = wiki_article.run_title_evaluation(model, tokenizer, \"wikitext-103-raw/wiki.valid.raw\")\n",
    "refined_model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = f\"\\\"TITLE\\\" is a song collaboration by Chinese artist Pamela Chen and Canadian singer Thomas Dimson, first released independently in March 2020. After gaining popularity amongst the cat community, the single was re-released by major label Columbia Records in May 2020. Pamela describes the song as being originally inspired by her two kittens, Apollo and Bean who once said meow.<bot>\"\n",
    "\n",
    "model =  modeling.GPT2LMHeadWithWeightedLossModel.from_pretrained(\"models/wikitext-103-raw-title-scale-20-lr5e-5\").to(\"cuda\")\n",
    "input = tokenizer.encode(sequence, return_tensors=\"pt\").to('cuda')\n",
    "generated = model.generate(input, max_length=100, num_return_sequences=100, temperature=1)\n",
    "\n",
    "print(f\"Prompt text: {sequence}\")\n",
    "for i in range(generated.size()[0]):\n",
    "    sentence_tokens = generated[i, :].tolist()\n",
    "    decoded = tokenizer.decode(sentence_tokens)\n",
    "    m = re.search(r\"<bot>(.*?)<eot>\", decoded)\n",
    "    if m:urban_dictionary_scraper\n",
    "        print(f\"{i}) {m.groups(1)}\")\n",
    "    else:\n",
    "        print(f\"{i}) Didn't work\")\n",
    "    \n",
    "\n",
    "resulting_string = tokenizer.decode(generated.tolist()[0])\n",
    "# print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in entries: \n",
    "    m = re.match(r\"\\s*\" + re.escape(entry.title) + r\"\\d*\\s*(\\|[^|]*\\|)?\\s*\", entry.entry_str)\n",
    "    if m:\n",
    "        trainable_entry = entry.entry_str[m.span()[1]:].strip()\n",
    "        if not trainable_entry:\n",
    "            raise RuntimeError(f\"Bad entry for {entry.title}: '{entry.entry_str}'\")\n",
    "    else:\n",
    "        raise RuntimeError(f\"Couldn't match {entry.title} on '{entry.entry_str}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_path = \"data/com_apple_MobileAsset_DictionaryServices_dictionaryOSX/69b7ab1cf0f75ad16bf6662b0a77fbfd36b7941f.asset/AssetData/New Oxford American Dictionary.dictionary/Contents/Resources/Body.data\"\n",
    "with open(dictionary_path, \"rb\") as f:\n",
    "    valid_words = {e.title.upper() for e in dictionary_definition.DictionaryDefinition.gen_from_apple_dictionary(f)}full_dataset = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load 'models/dictionary-scale-10-lr5e-5'. Make sure that:\n\n- 'models/dictionary-scale-10-lr5e-5' is either a correct model identifier of a community model from 'https://huggingface.co/models' which has a 'config.json' file\n\n- or 'models/dictionary-scale-10-lr5e-5' is a model name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl', 'distilgpt2']\n\n- or 'models/dictionary-scale-10-lr5e-5' is the correct path to a directory containing a 'config.json' file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/company-makeup/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, pretrained_config_archive_map, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresolved_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-dd75eb64c988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPT2LMHeadWithWeightedLossModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/dictionary-scale-10-lr5e-5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mblacklist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data/en_dictionary_parsed_randomized.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/company-makeup/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             )\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/company-makeup/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/company-makeup/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, pretrained_config_archive_map, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m                     )\n\u001b[1;32m    265\u001b[0m                 )\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load 'models/dictionary-scale-10-lr5e-5'. Make sure that:\n\n- 'models/dictionary-scale-10-lr5e-5' is either a correct model identifier of a community model from 'https://huggingface.co/models' which has a 'config.json' file\n\n- or 'models/dictionary-scale-10-lr5e-5' is a model name in ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl', 'distilgpt2']\n\n- or 'models/dictionary-scale-10-lr5e-5' is the correct path to a directory containing a 'config.json' file"
     ]
    }
   ],
   "source": [
    "model =  modeling.GPT2LMHeadWithWeightedLossModel.from_pretrained(\"models/dictionary-scale-10-lr5e-5\").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = dictionary_definition.generate_words(\n",
    "    tokenizer, model, allow_proper_nouns=False, blacklist=valid_words, num=1000, max_iterations=40\n",
    ")\n",
    "words.sort(key=lambda x: x.title)\n",
    "for w in words:\n",
    "    print(f\"{w} {w.entry_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"words.tsv\", \"w\") as f:\n",
    "    for word in words:\n",
    "        f.write(f\"{word.title}\\t{word.entry_str}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens(datasets.SpecialTokens.special_tokens_dict())\n",
    "blacklist = set((x.lower() for x in itertools.chain.from_iterable(\n",
    "    [e.word] + e.derivatives\n",
    "    for e in pickle.load(open(f\"data/en_dictionary_parsed_randomized.pickle\", \"rb\")))\n",
    "))\n",
    "model = AutoModelWithLMHead.from_pretrained(\"models/en_dictionary_parsed_lr_00005/checkpoint-50000\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilox /noun/\n",
      "\ta member of a North American Indian people living in the Carboniferous–Piloches Mountains in western New Mexico.\n",
      "\t\"when the Nilox was sent up by the Indians, the upper part of their bodies were burned to make it look like sheep meat\" [e]\n",
      "\n",
      "crestle /noun/\n",
      "\tan ornamental design resembling a cup.\n",
      "\t\"the cupboard in front was a throne on a crestle\" [e]\n",
      "\n",
      "pancre /noun/\n",
      "\ta hollowed wooden structure resembling pancake in shape.\n",
      "\t\"the pancre of his stomach\" [e]\n",
      "\n",
      "m.c. /abbreviation/\n",
      "\tmordant.\n",
      "\t\"we're looking at two new titles from the m.c. of Shakespeare\" [e]\n",
      "\n",
      "harpaloo /noun/\n",
      "\ta Hawaiian shrub of the berry family which has aromatic flowers and is widely grown for fodder.\n",
      "\t\"many of the country's most popular harpaloo shrubs are planted with mulch\" [e]\n",
      "\n",
      "socktail /noun/\n",
      "\ta piece of soft, sweet hair cut from small sashes, the hair of a female fish, or a person's breast.\n",
      "\t\"the men were given a free sample of the popular Socktail at the aquarium\" [e]\n",
      "\n",
      "gir /noun/\n",
      "\ta small edible fruit of the grape family, typically eaten with fruit juice or wine.\n",
      "\t\"choruses, girbons, nastles, and almonds\" [e]\n",
      "\n",
      "unadvised /adjective/\n",
      "\tnot intended to be taken seriously or taken into account\n",
      "\t\"the government was unadvised\"\n",
      "\n",
      "Mangoc /None/\n",
      "\tan industrial city in southwestern South Korea, capital of the Korean peninsula; population 190,300 (est. 2008).\n",
      "\t\"Mangoc's history includes the struggle for a unified Korean state before the Korean War\" [e]\n",
      "\n",
      "papillomania /noun/\n",
      "\ta condition in which a person is suffering from mental disabilities.\n",
      "\t\"papillomania is caused by the severity of symptoms\" [e]\n",
      "\n",
      "trichophagous /adjective/\n",
      "\t(of a bacteria or an organism) characterized by multicellular growth.\n",
      "\t\"the new treatment will need a trichophagous bacteria treatment\" [e]\n",
      "\n",
      "sodah /noun/\n",
      "\ta religious teacher or spiritual teacher.\n",
      "\t\"a soup served to the sodah\" [e]\n",
      "\n",
      "Moselle's disease /noun/\n",
      "\tan acute hereditary disease affecting horses, caused by a malignant bacterial infection and causing fever in horses.\n",
      "\t\"the first known Moselle's disease outbreak, in the US in 1938\" [e]\n",
      "\n",
      "bouck /verb [no object]/\n",
      "\ttake off clothes and dress quickly or loosely\n",
      "\t\"a bouck of cash\" [e]\n",
      "\n",
      "crememaster /noun/\n",
      "\ta person who paints or decorated another person's body in a catholic church or a other religious order.\n",
      "\t\"John of the Cross, on a crememaster, had been burned for his participation in the Christian Church\" [e]\n",
      "\n",
      "reinterpreter /noun/\n",
      "\tan opponent whoencer who can react rapidly to the action of a ball, to make a further stroke, and or to control the motion of an opponent.\n",
      "\t\"he plays a good catch, and reinterpreters his parrying ball\" [e]\n",
      "\n",
      "sextession /noun/\n",
      "\tan act of enticement.\n",
      "\t\"they had won their second sextession\" [e]\n",
      "\n",
      "pump-off /adjective/\n",
      "\tunready to change or improve\n",
      "\t\"the price of oil has gone up with the pump-off\"\n",
      "\n",
      "cacadillo /adjective/\n",
      "\ta tall-and-strong rock musician.\n",
      "\t\"Cacadillo live in Los Angeles and performcountry music regularly\" [e]\n",
      "\n",
      "outreachment /noun/\n",
      "\ta way or path taken\n",
      "\t\"the journey was a long outdoor outreachment\"\n",
      "\n",
      "stalkie /noun/\n",
      "\ta person who stalks or harasses someone (often as an online form of address)\n",
      "\t\"the stalkie for you?\"\n",
      "\n",
      "sempatriches /plural noun/\n",
      "\ta group of people or things regarded as constituting a whole\n",
      "\t\"the sempatriches of the English language\"\n",
      "\n",
      "unadvised /adjective/\n",
      "\tnot properly planned; rushed\n",
      "\t\"an unadvised audience\"\n",
      "\n",
      "selficentric /adjective/\n",
      "\t(of a person or their beliefs) holding or thinking of oneself independently of the external world.\n",
      "\t\"a selficentric society\" [e]\n",
      "\n",
      "Bouilly's Island /None/\n",
      "\tan open island in the British Antarctic Ocean that forms part of the Great Rift Valley. The southern boundary of the island of New Guinea.\n",
      "\t\"the Bouilly's Island National Park\" [e]\n",
      "\n",
      "nail-dry /verb [no object, with adverbial of direction]/\n",
      "\t(of a part of one's body) become exposed to moisture\n",
      "\t\"her skin had become nail-dry to the wind\"\n",
      "\n",
      "curtamen /noun/\n",
      "\ta woman's chest or chest area, especially when covered with cloth.\n",
      "\t\"her curtamen belt\" [e]\n",
      "\n",
      "Pecos Islands /None/\n",
      "\ta group of 4 volcanic islands off the southwestern coast of New Zealand that constitute the mainland of New Zealand.\n",
      "\t\"the investigation into the Pecos Islands was carried out by the Coast Guard on a high-level basis\" [e]\n",
      "\n",
      "charlangize /verb [with object]/\n",
      "\tmake superior or superior to\n",
      "\t\"charlangize themselves by the strength of their work\" [e]\n",
      "\n",
      "unreward /verb [with object]/\n",
      "\tcause great pleasure or gain without satisfaction\n",
      "\t\"the restaurant offers excellent food and drinks but it's not unrewarding on its menu\"\n",
      "\n",
      "cantoon /noun/\n",
      "\ta cantelet.\n",
      "\t\"a cantoon of black silk\" [e]\n",
      "\n",
      "thymotaxis /noun/\n",
      "\ta process of turning an organ into a thymoid or another similar vessel by a tapering of the surface.\n",
      "\t\"the tubulets are a common example of the use of thymotaxis techniques\" [e]\n",
      "\n",
      "breechback /noun/\n",
      "\ta large hairy rodent related to the rats, originating in Australia and now chiefly in New Guinea and New Island, native to the tropics.\n",
      "\t\"a great breechback, the Old Bowerman, and the New Bowermans are now common on the northeastern island of New Guinea\" [e]\n",
      "\n",
      "dichymalism /noun/\n",
      "\ta belief, attitude, or belief system characterized by excessively cautious optimism\n",
      "\t\"my parents are worried about how my devious views and dichymalism will influence my family\"\n",
      "\n",
      "prosode /verb [with object]/\n",
      "\tdestroy; fail to achieve\n",
      "\t\"exteriorism and prosode in office\"\n",
      "\n",
      "Papalto /adjective/\n",
      "\trelating to or characteristic of the Italian city of Paris or its inhabitants\n",
      "\t\"a restaurant that speaks Italian and Papalto music\"\n",
      "\n",
      "concatenative /noun/\n",
      "\ta conjunction.\n",
      "\t\"for every pair of words the speaker uses one concatenative\" [e]\n",
      "\n",
      "luteo /noun/\n",
      "\tan Italian dish containing meat that has been cut, fried, cooked, or otherwise marinated.\n",
      "\t\"a Luteo sauce\" [e]\n",
      "\n",
      "garden-garden /noun/\n",
      "\tthe territory of a large town, especially a village or college town.\n",
      "\t\"the city, with its numerous urban and garden-garden hills, was the center of the world's industrial giant\" [e]\n",
      "\n",
      "furnice center /noun/\n",
      "\ta restaurant or bar serving hot wings, salads, etc.\n",
      "\t\"the furnice center is located in the village center\" [e]\n",
      "\n",
      "materia /noun/\n",
      "\tthe quality of being melodramatic.\n",
      "\t\"a rich, Materia song\" [e]\n",
      "\n",
      "waxed /adjective/\n",
      "\thaving waxed or waxed wings.\n",
      "\t\"a waxed cat\" [e]\n",
      "\n",
      "fernbark /noun/\n",
      "\tan American wild apple of a kind that is native to southeastern Europe. It is commercially valuable for its crisp dark brown plumage, but many farmers produce fernbark and other hardy varieties.\n",
      "\t\"fernbark apples\" [e]\n",
      "\n",
      "tactemister /noun/\n",
      "\ta person who acts as an agent for another by assisting them in their work.\n",
      "\t\"a man of war with an army Tactemister of the spirit of war\" [e]\n",
      "\n",
      "transmogamy /noun/\n",
      "\t(in Jewish law) marriage between one person and another to a person's spouse.\n",
      "\t\"the couple's attempt to make love to their son, as their transmogamy grew, was defeated by repeated attacks\" [e]\n",
      "\n",
      "Mtivoli /noun/\n",
      "\ta person holding the title of general in the Roman Catholic Church.\n",
      "\t\"Mtivoli was often seen as the patron saint of the press\" [e]\n",
      "\n",
      "seapower /noun/\n",
      "\ta wall or room designed to preserve sea slugs.\n",
      "\t\"a seapower at the bottom of a deep blue sea\" [e]\n",
      "\n",
      "nurse-maid /noun/\n",
      "\ta female nurse who teaches the baby or other child, especially in some churches or clinics.\n",
      "\t\"the first nurse-maid was the nurse in the Baptist Church\" [e]\n",
      "\n",
      "MbE /abbreviation/\n",
      "\tMaster of Biology (in medical names).\n",
      "\t\"MbE research\" [e]\n",
      "\n",
      "trenchcoat /noun/\n",
      "\ta coat made from or containing a trench coat.\n",
      "\t\"he dressed in trenchcoats to cut back on excess snow\" [e]\n",
      "\n",
      "trimpoteness /noun/\n",
      "\tthe degree to which something is slim\n",
      "\t\"trim the shoulders into trimpoteness\" [e]\n",
      "\n",
      "sapel /noun/\n",
      "\ta thin, round piece of bacon held on a skewer and baked.\n",
      "\t\"he served up a chicken sapel\" [e]\n",
      "\n",
      "waxse /verb [with object]/\n",
      "\tcoat or treat with wax.\n",
      "\t\"he waxse his hair in front of the mirror\" [e]\n",
      "\n",
      "Ciudad delíviros /None/\n",
      "\ta city in northeastern Brazil, capital of the state of Boscara; population 442,450 (2007).\n",
      "\t\"the historic center of Ciudad delíviros is the city, located in the valley of the border with Peru\" [e]\n",
      "\n",
      "pomoelectric /adjective/\n",
      "\tconsisting of one or more pomoelectric plates, consisting of a mixture of one atom of carbon atom of hydrogen and one electron of iron and produced by a chain reaction.\n",
      "\t\"pomoelectric atoms\" [e]\n",
      "\n",
      "cauterade /noun/\n",
      "\ta series of movements between a group of seats in a theater that is usually closed after being replaced by a smaller version.\n",
      "\t\"an audience of 20 people was watching at the end of the cauterade\" [e]\n",
      "\n",
      "dewtail /noun/\n",
      "\ta female worm, especially one which feeds exclusively on the blood, as viewed from a cuckoo.\n",
      "\t\"the dewtail is an especially attractive female worm\" [e]\n",
      "\n",
      "baille /verb [with object]/\n",
      "\tsecure the payment of (a debt)\n",
      "\t\"a bank that will baille mortgage debt\" [e]\n",
      "\n",
      "nondress /verb/\n",
      "\tremove or separate from a woman or girl or a girlhood\n",
      "\t\"he nondressed back into his man's style\" [e]\n",
      "\n",
      "mulcipal /noun/\n",
      "\ta person who kills his or her father.\n",
      "\t\"a man who commits murder, typically one who is himself a mulcipal\" [e]\n",
      "\n",
      "cogne /noun/\n",
      "\tthe stomach wall of a deer or mule.\n",
      "\t\"the dog's cogne was covered with black\" [e]\n",
      "\n",
      "bundle-bag /noun/\n",
      "\ta small bag filled with things taken from a vehicle.\n",
      "\t\"a bundle-bag of flowers\" [e]\n",
      "\n",
      "Pisidodactyl /adjective/\n",
      "\trelating to the Pisidian dynasty or its dynasty.\n",
      "\t\"the dynasty was ruled by Pisidodactyl palaces\" [e]\n",
      "\n",
      "Camberedon /None/\n",
      "\ta port and resort on the Atlantic coast of southeastern Louisiana, on the Atlantic Ocean, southwest of New Orleans; population 96,294 (2000). It established its national championship in 1912 and later hosted the US Open 1914–19.\n",
      "\t\"a wine-bar gastropub, the Camberedon\" [e]\n",
      "\n",
      "sluggy /adjective/\n",
      "\thasty or clumsy\n",
      "\t\"she had a sluggy metabolism\"\n",
      "\n",
      "unbeneath /preposition/\n",
      "\tbelow (before an idea)\n",
      "\t\"an unbeneath question\" [e]\n",
      "\n",
      "nonjudice /noun/\n",
      "\tthe principles or belief that distinguish humans and other animals\n",
      "\t\"a principle of nonjudice\" [e]\n",
      "\n",
      "Cherita /None/\n",
      "\ta city in southeastern Louisiana, northeast of New Orleans; population 56,873 (est. 2008).\n",
      "\t\"a Cherita prison\" [e]\n",
      "\n",
      "hooboy /noun/\n",
      "\ta hairdresser of hoo-dah\n",
      "\t\"his hair is a lot of hooboy\" [e]\n",
      "\n",
      "trenchcoat /verb [with object]/\n",
      "\tcoat (an area of the body) with trenchcoat.\n",
      "\t\"he trenchcoated his body with warm water\" [e]\n",
      "\n",
      "unlaced /adjective/\n",
      "\tcompletely unfaced or exposed.\n",
      "\t\"a landscape of unlaced fields\" [e]\n",
      "\n",
      "seaworn /adjective/\n",
      "\thaving been made to resemble a sleeveless garment without the top being pulled tight\n",
      "\t\"seaworn glasses\"\n",
      "\n",
      "inferring /noun/\n",
      "\tan amount of something mentioned in a preceding statement, especially one that serves as evidence of its quantity\n",
      "\t\"the car's inferring from a different driver\" [e]\n",
      "\n",
      "dichymosis /noun/\n",
      "\ta disorder of the nervous system containing undifferentiated cells, caused mainly by dichymosis and sometimes accompanied by damage to cells.\n",
      "\t\"new studies have shown a significant reduction in dichymosis in the elderly\" [e]\n",
      "\n",
      "transylasticity /noun/\n",
      "\tthe quality or condition of being easily split into smaller pieces\n",
      "\t\"the transylasticity of the interwoven fabric\"\n",
      "\n",
      "slip-top /noun/\n",
      "\ta small sliding chair for holding or supporting a tray containing food such as a slice of bread\n",
      "\t\"slip-top windows\"\n",
      "\n",
      "thripe /adjective/\n",
      "\t(of an animal or person) of a throrotatory or carnivorous kind\n",
      "\t\"farther in this breed my sister's are a little thripe\"\n",
      "\n",
      "ex-loyal /adjective/\n",
      "\thaving no loyalty to anyone\n",
      "\t\"an ex-loyal member of the armed services\"\n",
      "\n",
      "shamper /noun/\n",
      "\ta small metal enclosure or small tower forming part of a larger one.\n",
      "\t\"the shamper housing\" [e]\n",
      "\n",
      "conjute /verb/\n",
      "\tarrange an impassive or offensive remark.\n",
      "\t\"the writer conjutes a plot to be much darker and more dramatic\" [e]\n",
      "\n",
      "stiff-hewn /adjective/\n",
      "\t(especially of a rope or knot) having a loose, stiff, and untidy shape; untidy\n",
      "\t\"a stiff-hewn knot\"\n",
      "\n",
      "Mackinawea River /None/\n",
      "\ta river that flows for 1,200 miles (3,380 km) from east central Mississippi through Mexico into the Rio Grande valley.\n",
      "\t\"he was killed while riding in the Mackinawea River with four partners\" [e]\n",
      "\n",
      "chlorothane /noun/\n",
      "\ta colorless, poisonous liquid crystalline compound used in making synthetic and perfumes.\n",
      "\t\"chlorothane is used as an insecticide\" [e]\n",
      "\n",
      "nephus /noun/\n",
      "\ta herbaceous plant of the daisy family, cultivated for its medicinal properties, native to the Middle East.\n",
      "\t\"a traditional dish of nephus\" [e]\n",
      "\n",
      "scroogryphilia /noun/\n",
      "\tsexual activity intended to achieve sexual gratification via the mutual exchange of personal information.\n",
      "\t\"the practice has developed to become recognized as the most dangerous form of scroogryphilia\" [e]\n",
      "\n",
      "gutting /noun/\n",
      "\ta person's stomach.\n",
      "\t\"she was a gutting little boy\" [e]\n",
      "\n",
      "dichy /adjective [attributive]/\n",
      "\tdenoting the shape or appearance of a liquid\n",
      "\t\"a dichy pink accent\" [e]\n",
      "\n",
      "disappraise /verb [with object]/\n",
      "\tmake (the sun) lower\n",
      "\t\"the sun's lower shade of yellow to disappraise the sun\" [e]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = datasets.ParsedDictionaryDefinitionDataset.generate_words(\n",
    "    tokenizer, model, max_iterations=10, blacklist=blacklist, do_example_expansion=True,\n",
    ")\n",
    "for word in words:\n",
    "    print(f\"{word.word} /{word.pos}/\")\n",
    "    print(f\"\\t{word.definition}\")\n",
    "    print(f\"\\t\\\"{word.example}\\\"{' [e]' if word.from_example_expansion else ''}\")\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from datasets import SpecialTokens\n",
    "\"\"\"\n",
    "input_str = f\"{tokenizer.bos_token}\"\n",
    "input_str = \"<|bod|>corner<|pos|>noun<|bd|>a point or space in a hierarchy that is within the order to which it moves along the axis.<|eod|>\"\n",
    "input = tokenizer.encode(input_str, return_tensors=\"pt\").to(\"cuda\")\n",
    "max_length = 512\n",
    "\n",
    "generated = model.generate(\n",
    "    input_ids=input, \n",
    "    max_length=max_length, \n",
    "    num_return_sequences=5, \n",
    "    temperature=1.0,\n",
    "    top_k=1000,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_ids=tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    ")\n",
    "\n",
    "break_specials = [\n",
    "    SpecialTokens.BOS_TOKEN, SpecialTokens.EOS_TOKEN, SpecialTokens.DEFINITION_SEP,\n",
    "    SpecialTokens.EXAMPLE_SEP, SpecialTokens.TOPIC_SEP, SpecialTokens.POS_SEP \n",
    "]\n",
    "break_special_ids = [tokenizer.encode(e, add_prefix_space=False)[0] for e in break_specials]\n",
    "break_special_token_map = {s: i for s, i in zip(break_specials, break_special_ids)}\n",
    "\n",
    "\n",
    "for i in range(generated.size()[0]):\n",
    "    sentence_tokens = generated[i, :].tolist()\n",
    "    \n",
    "    \n",
    "    accum = []\n",
    "    last_special = None\n",
    "    sep_map = {}\n",
    "    for token_id in sentence_tokens:\n",
    "        if token_id in break_special_ids:\n",
    "            if last_special is not None:\n",
    "                sep_map[last_special] = accum\n",
    "                accum = []\n",
    "                last_special = token_id\n",
    "            else:\n",
    "                last_special = token_id\n",
    "        else:\n",
    "            accum.append(token_id)\n",
    "            \n",
    "    sep_map[last_special] = accum\n",
    "    accum = []\n",
    "    \n",
    "    decode_sep_map = {\n",
    "        tokenizer.decode([k]): tokenizer.decode(v) for k, v in sep_map.items()\n",
    "    }\n",
    "        \n",
    "    print(decode_sep_map)\n",
    "    \n",
    "    # decoded = tokenizer.decode([e for e in sentence_tokens if e != tokenizer.pad_token_id])\n",
    "    print(decoded)  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a bc'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"a bc\", add_prefix_space=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|bod|>',\n",
       " 'eos_token': '<|eod|>',\n",
       " 'unk_token': '<|endoftext|>',\n",
       " 'pad_token': '<|pad|>',\n",
       " 'additional_special_tokens': ['<|bd|>', '<|be|>', '<|pos|>', '<|bto|>']}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = set(e.title for e in pickle.load(open(\"data/all_words.pickle\", \"rb\")).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation: tried 350, failed 102 (0.29), no word in example 121 (0.49), filtered from blacklist 12 (0.09)\n"
     ]
    }
   ],
   "source": [
    "model =  modeling.GPT2LMHeadWithWeightedLossModel.from_pretrained(\n",
    "    \"models/urban_dictionary_cleaned_top_def_mu02_lr_0_000005_tw40\"\n",
    ").to(\"cuda\")\n",
    "tw40_words = urban_dictionary_scraper.generate_words(\n",
    "    tokenizer,\n",
    "    model,\n",
    "    blacklist=blacklist,\n",
    "    num=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tw1_words, open(\"data/labeling/tw1_words.pickle\", \"wb\"), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(tw40_words, open(\"data/labeling/tw40_words.pickle\", \"wb\"), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        (\n",
    "            word.word,\n",
    "            word.definition,\n",
    "            word.example.replace(,\n",
    "            \"tw1\" if i < len(tw1_words) else \"tw2\",\n",
    "        )\n",
    "        for i, word in enumerate(itertools.chain(\n",
    "            tw1_words,\n",
    "            tw40_words\n",
    "        ))\n",
    "    ],\n",
    "    columns=(\"word\", \"definition\", \"example\", \"dataset\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_no_dataset = sample[:]\n",
    "sample_no_dataset.to_csv(\"fun.csv\", index=False, columns=[\"word\", \"definition\", \"example\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ipywidgets.widgets.interaction._InteractFactory at 0x7fe66fbe9f10>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens(datasets.SpecialTokens.special_tokens_dict())\n",
    "model =  AutoModelWithLMHead.from_pretrained(\"models/en_dictionary_parsed_lr_00005/checkpoint-50000\").to(\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
